{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EIUmjkUQVPgG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from random import randrange\n",
        "import shutil\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the path for the 'dataset' directory\n",
        "dataset_dir = os.path.join(\"\", \"dataset\")\n",
        "# Create the 'dataset' directory if it doesn't exist\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "# Print the list of files and directories in the 'dataset' directory\n",
        "print(os.listdir(dataset_dir))\n",
        "\n",
        "# Create the path for the 'updatedDataset' directory\n",
        "updated_dataset_dir = os.path.join(\"\", \"updatedDataset\")\n",
        "# Create the 'updatedDataset' directory if it doesn't exist\n",
        "os.makedirs(updated_dataset_dir, exist_ok=True)\n",
        "# Print the list of files and directories in the 'updatedDataset' directory\n",
        "print(os.listdir(updated_dataset_dir))\n",
        "\n",
        "# 4K format dimensions for height and width\n",
        "H = 440.0\n",
        "B = 440.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFVIYeA8VWgc",
        "outputId": "a33000ee-cc39-4fba-aa31-9456c3eeb615"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Screenshot_Room7_LeftWall_Bathtub1_Faucet_Bathtub1_Floor1_Wall1_Time0_Camera_0.jpg', '.DS_Store', 'Screenshot_Room7_LeftWall_Bathtub1_Faucet_Bathtub1_Floor1_Wall1_Time0_Camera_0.txt', 'Screenshot_Room7_LeftWall_Bathtub1_Faucet_Bathtub1_Floor1_Wall1_Time0_Camera_5.jpg', 'Screenshot_Room7_LeftWall_Bathtub1_Faucet_Bathtub1_Floor1_Wall1_Time0_Camera_5.txt']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_names(folder_path, format=\".txt\"):\n",
        "    # Check if the format is \".txt\"\n",
        "    if format == \".txt\":\n",
        "        # List comprehension to find all files ending with '.txt' in the specified folder\n",
        "        txt_labels = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.txt')]\n",
        "        # Return the list of txt file names\n",
        "        return txt_labels\n",
        "\n",
        "def check_update_outliers(updated_x, updated_y, side_size_x, side_size_y):\n",
        "    # Check if the right edge of the bounding box exceeds the right boundary (1.0)\n",
        "    if updated_x + side_size_x / 2 > 1:\n",
        "        # Adjust the x coordinate to bring the bounding box within the boundary\n",
        "        updated_x = updated_x - (updated_x + side_size_x / 2 - 1) / 2\n",
        "        # Adjust the width of the bounding box to fit within the boundary\n",
        "        side_size_x = 2 * (1 - updated_x)\n",
        "    # Check if the left edge of the bounding box exceeds the left boundary (0.0)\n",
        "    elif updated_x - side_size_x / 2 < 0:\n",
        "        # Adjust the x coordinate to bring the bounding box within the boundary\n",
        "        updated_x = updated_x + (side_size_x / 2 - updated_x) / 2\n",
        "        # Adjust the width of the bounding box to fit within the boundary\n",
        "        side_size_x = 2 * updated_x\n",
        "\n",
        "    # Check if the top edge of the bounding box exceeds the top boundary (1.0)\n",
        "    if updated_y + side_size_y / 2 > 1:\n",
        "        # Adjust the y coordinate to bring the bounding box within the boundary\n",
        "        updated_y = updated_y - (updated_y + side_size_y / 2 - 1) / 2\n",
        "        # Adjust the height of the bounding box to fit within the boundary\n",
        "        side_size_y = 2 * (1 - updated_y)\n",
        "    # Check if the bottom edge of the bounding box exceeds the bottom boundary (0.0)\n",
        "    elif updated_y - side_size_y / 2 < 0:\n",
        "        # Adjust the y coordinate to bring the bounding box within the boundary\n",
        "        updated_y = updated_y + (side_size_y / 2 - updated_y) / 2\n",
        "        # Adjust the height of the bounding box to fit within the boundary\n",
        "        side_size_y = 2 * updated_y\n",
        "\n",
        "    # Check for the corners where both X and Y boundaries are exceeded\n",
        "    # Bottom-left corner\n",
        "    if (updated_x - side_size_x / 2 < 0) and (updated_y - side_size_y / 2 < 0):\n",
        "        # Adjust both x and y coordinates to bring the bounding box within the boundary\n",
        "        updated_x = side_size_x / 2\n",
        "        updated_y = side_size_y / 2\n",
        "\n",
        "    # Bottom-right corner\n",
        "    if (updated_x + side_size_x / 2 > 1) and (updated_y - side_size_y / 2 < 0):\n",
        "        # Adjust both x and y coordinates to bring the bounding box within the boundary\n",
        "        updated_x = 1 - side_size_x / 2\n",
        "        updated_y = side_size_y / 2\n",
        "\n",
        "    # Top-left corner\n",
        "    if (updated_x - side_size_x / 2 < 0) and (updated_y + side_size_y / 2 > 1):\n",
        "        # Adjust both x and y coordinates to bring the bounding box within the boundary\n",
        "        updated_x = side_size_x / 2\n",
        "        updated_y = 1 - side_size_y / 2\n",
        "\n",
        "    # Top-right corner\n",
        "    if (updated_x + side_size_x / 2 > 1) and (updated_y + side_size_y / 2 > 1):\n",
        "        # Adjust both x and y coordinates to bring the bounding box within the boundary\n",
        "        updated_x = 1 - side_size_x / 2\n",
        "        updated_y = 1 - side_size_y / 2\n",
        "\n",
        "    # Return the potentially adjusted coordinates and sizes\n",
        "    return updated_x, updated_y, side_size_x, side_size_y\n",
        "\n",
        "def update_normalize_xy(param, side_size, dimension=\"X\", H=440., B=440.):\n",
        "    \"\"\"\n",
        "    Normalizes the param value for the specified dimension (X or Y).\n",
        "\n",
        "    Args:\n",
        "    param (float): The parameter value to normalize.\n",
        "    side_size (float): The size to be added for centering.\n",
        "    dimension (str): The dimension to normalize ('X' or 'Y').\n",
        "    H (float): The maximum range for X dimension (default is 3840.0).\n",
        "    B (float): The maximum range for Y dimension (default is 2160.0).\n",
        "\n",
        "    Returns:\n",
        "    float: The normalized parameter value in the range [0, 1].\n",
        "\n",
        "    Raises:\n",
        "    ValueError: If the dimension is not 'X' or 'Y'.\n",
        "    \"\"\"\n",
        "    if dimension == \"X\":\n",
        "        # Normalize the param value for the X dimension\n",
        "        return (param + side_size / 2) / H\n",
        "    elif dimension == \"Y\":\n",
        "        # Normalize the param value for the Y dimension\n",
        "        return (param + side_size / 2) / B\n",
        "    else:\n",
        "        raise ValueError(\"Dimension must be 'X' or 'Y'\")\n",
        "\n",
        "def change_label_content(path, updated_path):\n",
        "    # Initialize variables to hold label index, coordinates, and sizes\n",
        "    index = 0\n",
        "    updated_x = 0\n",
        "    updated_y = 0\n",
        "    side_size_x = 0\n",
        "    side_size_y = 0\n",
        "\n",
        "    sts = []\n",
        "\n",
        "    # Open the file at the given path in read mode\n",
        "    with open(path, \"r\") as fileref:\n",
        "        # Iterate over each line in the file\n",
        "        for i in fileref:\n",
        "            # Split the line into parts and parse the values as floats\n",
        "            name = i.split(\" \")[0]\n",
        "            index1 = (i.split(\" \")[1])\n",
        "            index2 = (i.split(\" \")[2])\n",
        "            updated_x = float(i.split(\" \")[3])\n",
        "            updated_y = float(i.split(\" \")[4])\n",
        "            side_size_x = float(i.split(\" \")[5])\n",
        "            side_size_y = float(i.split(\" \")[6])\n",
        "\n",
        "            # Normalize the x and y coordinates\n",
        "            updated_x = update_normalize_xy(updated_x, side_size_x, \"X\")\n",
        "            updated_y = update_normalize_xy(updated_y, side_size_y, \"Y\")\n",
        "\n",
        "            # Normalize the side sizes (assuming H and B are global or defined elsewhere)\n",
        "            side_size_x = side_size_x / H\n",
        "            side_size_y = side_size_y / B\n",
        "\n",
        "            updated_x, updated_y, side_size_x, side_size_y = check_update_outliers(updated_x, updated_y, side_size_x, side_size_y)\n",
        "\n",
        "            # Create a string with updated values concatenated\n",
        "            st = f\"{name} {index1} {index2} {updated_x} {updated_y} {side_size_x} {side_size_y}\"\n",
        "            sts.append(st)\n",
        "\n",
        "    # Open the file at the given path in write mode and write the updated string\n",
        "    with open(updated_path, \"w\") as file:\n",
        "      print(sts)\n",
        "      file.writelines(sts)"
      ],
      "metadata": {
        "id": "m4nEWxdzagGY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_jpg_images(folder_path, format=\".jpg\"):\n",
        "    # Initialize counters for jpg and txt files\n",
        "    jpg_count = 0\n",
        "    txt_count = 0\n",
        "\n",
        "    # Check the format parameter to determine which files to count\n",
        "    if format == \".jpg\":\n",
        "        # Loop through all files in the specified folder\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            # Check if the file name ends with '.jpg'\n",
        "            if file_name.endswith('.jpg'):\n",
        "                # Increment the jpg file count\n",
        "                jpg_count += 1\n",
        "        # Return the count of jpg files\n",
        "        return jpg_count\n",
        "    elif format == \".txt\":\n",
        "        # Loop through all files in the specified folder\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            # Check if the file name ends with '.txt'\n",
        "            if file_name.endswith('.txt'):\n",
        "                # Increment the txt file count\n",
        "                txt_count += 1\n",
        "        # Return the count of txt files\n",
        "        return txt_count\n",
        "\n",
        "def get_jpg_image_names(folder_path, format=\".jpg\"):\n",
        "    # Check if the format is \".jpg\"\n",
        "    if format == \".jpg\":\n",
        "        # List comprehension to find all files ending with '.jpg' in the specified folder\n",
        "        jpg_images = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.jpg')]\n",
        "        # Return the list of jpg file names\n",
        "        return jpg_images\n",
        "    else:\n",
        "        # List comprehension to find all files ending with '.txt' in the specified folder\n",
        "        txt_images = [file_name for file_name in os.listdir(folder_path) if file_name.endswith('.txt')]\n",
        "        # Return the list of txt file names\n",
        "        return txt_images\n",
        "\n",
        "def copy_image(src_folder, dest_folder, image_name):\n",
        "    # Ensure the destination folder exists\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    # Define the full file paths\n",
        "    src_path = os.path.join(src_folder, image_name)\n",
        "    dest_path = os.path.join(dest_folder, image_name)\n",
        "\n",
        "    # Copy the image\n",
        "    shutil.copy(src_path, dest_path)\n",
        "\n",
        "def copy_file(src_folder, dest_folder, file_name):\n",
        "    # Ensure the destination folder exists\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "\n",
        "    # Define the full file paths\n",
        "    src_path = os.path.join(src_folder, file_name)\n",
        "    dest_path = os.path.join(dest_folder, file_name)\n",
        "\n",
        "    # Copy the file\n",
        "    shutil.copy(src_path, dest_path)\n",
        "\n",
        "def copy_all_images(src_folder, dest_folder, image_names):\n",
        "  for image_name in image_names:\n",
        "     copy_image(src_folder, dest_folder, image_name)\n",
        "\n",
        "def split_data():\n",
        "    # Define directories for dataset, training images, validation images, training labels, and validation labels\n",
        "    dataset_dir = 'dataset'\n",
        "    image_train_dir = 'images/train'\n",
        "    image_val_dir = 'images/val'\n",
        "    labels_train_dir = 'labels/train'\n",
        "    labels_val_dir = 'labels/val'\n",
        "\n",
        "    # Count the number of jpg images in the dataset directory\n",
        "    number_of_images = count_jpg_images(dataset_dir)\n",
        "\n",
        "    # Get the list of jpg image names in the dataset directory\n",
        "    image_names = get_jpg_image_names(dataset_dir)\n",
        "    # Dictionary to store image names and their corresponding random index\n",
        "    image_names_index = {}\n",
        "\n",
        "    # Get the list of txt label names in the dataset directory\n",
        "    label_names = get_jpg_image_names(dataset_dir, \".txt\")\n",
        "    # Dictionary to store label names and their corresponding random index\n",
        "    label_names_index = {}\n",
        "\n",
        "    # Lists to store the names of the labels for training and validation sets\n",
        "    labels_names_train = []\n",
        "    labels_names_val = []\n",
        "\n",
        "    # Add image and label names into the dictionaries with random index values\n",
        "    for i in range(len(image_names)):\n",
        "        image_names_index[image_names[i]] = randrange(10)\n",
        "        label_names_index[label_names[i]] = image_names_index[image_names[i]]\n",
        "\n",
        "    # Split images and labels into training and validation sets\n",
        "    for i in range(number_of_images):\n",
        "        # If the random index is 9 or 0, consider it for validation set\n",
        "        if list(image_names_index.values())[i] == 9 or list(image_names_index.values())[i] == 0:\n",
        "            # Copy image to validation directory\n",
        "            copy_image(dataset_dir, image_val_dir, list(image_names_index.keys())[i])\n",
        "            # Copy label to validation directory\n",
        "            copy_file(dataset_dir, labels_val_dir, list(label_names_index.keys())[i])\n",
        "            # Add label name to validation list\n",
        "            labels_names_val.append(list(label_names_index.keys())[i])\n",
        "        else:\n",
        "            # Otherwise, consider it for training set\n",
        "            # Copy image to training directory\n",
        "            copy_image(dataset_dir, image_train_dir, list(image_names_index.keys())[i])\n",
        "            # Copy label to training directory\n",
        "            copy_file(dataset_dir, labels_train_dir, list(label_names_index.keys())[i])\n",
        "            # Add label name to training list\n",
        "            labels_names_train.append(list(label_names_index.keys())[i])\n",
        "\n",
        "    # Return the lists of validation and training label names\n",
        "    return labels_names_val, labels_names_train\n",
        "\n",
        "\n",
        "def update_label_id(label_names, path, product_type_id):\n",
        "    names = {}\n",
        "    # Loop through each label name in the provided list\n",
        "    for index in range(len(label_names)):\n",
        "        # Open the current label file in read mode\n",
        "        with open(path + \"/\" + label_names[index], \"r\") as fileref:\n",
        "            # Initialize an empty string to store the new label content\n",
        "            st = \"\"\n",
        "            # Read each line in the file\n",
        "            for i in fileref:\n",
        "                # Check if the second element in the line matches the product_type_id\n",
        "                if product_type_id == int(i.split()[1]):\n",
        "\n",
        "                    # Update the string with the elements after the second one\n",
        "                    st_helper1= int(i.split()[2]) - 1\n",
        "                    st_helper2 = \" \".join(i.split()[3:])\n",
        "                    st = (str(st_helper1) + \" \" + str(st_helper2))\n",
        "\n",
        "                    names[st_helper1] = i.split()[0]\n",
        "                else:\n",
        "                    if not st: # if the string is empty\n",
        "                        st = \"\" # string should stay empty\n",
        "\n",
        "        # Open the same file in write mode to update its content\n",
        "        with open(path + \"/\" + label_names[index], 'w') as file:\n",
        "            # Write the updated string to the file\n",
        "            file.write(st)\n",
        "    print(names)\n",
        "    return names\n",
        "\n",
        "def update_label_names(label_names, path, product_type_list_names=[]):\n",
        "    # Initialize an empty string to store the new label content\n",
        "    st = \"\"\n",
        "    names = {}\n",
        "\n",
        "    # save all groups in list\n",
        "    all_groups = [] # liste mit neuen namen\n",
        "    for element_name in product_type_list_names:\n",
        "        all_groups.append(element_name)\n",
        "\n",
        "    # Create a dictionary that maps each group to an integer, so that we start counting from 0\n",
        "    newLabel_from0 = {group: index for index, group in enumerate(all_groups)}\n",
        "    newGroup_from0 = {index: group for group, index in newLabel_from0.items()}\n",
        "\n",
        "    # Loop through each label name in the provided list\n",
        "    for index in range(len(label_names)):\n",
        "        # Open the current label file in read mode\n",
        "        with open(path + \"/\" + label_names[index], \"r\") as fileref:\n",
        "            # Read each line in the file\n",
        "            for i in fileref:\n",
        "                # Check if the second element in the line matches the product_type_id\n",
        "                for j in product_type_list_names: # Sink\n",
        "                    if products[j] == int(i.split()[1]):\n",
        "\n",
        "                        newID = newLabel_from0.get(j)\n",
        "                        st_helper1 = str(newID)\n",
        "                        # Update the string with the elements after the third one\n",
        "                        st_helper2 = \" \".join(i.split()[3:])\n",
        "                        # Update the string with the elements after the third one\n",
        "                        st = (str(st_helper1) + \" \" + str(st_helper2))\n",
        "\n",
        "                        names[newID] = newGroup_from0[newID]\n",
        "                    else:\n",
        "                        if not st: # if the string is empty\n",
        "                            st = \"\" # string should stay empty\n",
        "\n",
        "\n",
        "        # Open the same file in write mode to update its content\n",
        "        with open(path + \"/\" + label_names[index], 'w') as file:\n",
        "            # Write the updated string to the file\n",
        "            file.write(st)\n",
        "    print(names)\n",
        "    return names\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_yolo_training_config(folder_path, product_specific=False, product_type_id=None, product_type_list_names=None):\n",
        "    # Ensure the path exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    # Create the folder structure\n",
        "    images_train_dir = os.path.join('images', 'train')\n",
        "    images_val_dir = os.path.join('images', 'val')\n",
        "    labels_train_dir = os.path.join('labels', 'train')\n",
        "    labels_val_dir = os.path.join('labels', 'val')\n",
        "\n",
        "    os.makedirs(images_train_dir, exist_ok=True)\n",
        "    os.makedirs(images_val_dir, exist_ok=True)\n",
        "    os.makedirs(labels_train_dir, exist_ok=True)\n",
        "    os.makedirs(labels_val_dir, exist_ok=True)\n",
        "\n",
        "    dataset_dir = os.path.join(\"\", \"updatedDataset\")\n",
        "    os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "    labels_names_val, labels_names_train = split_data()\n",
        "\n",
        "    products = {\"Toilet\":0, \"Bathtub\":1, \"Sink\":2}\n",
        "\n",
        "    if product_specific==True:\n",
        "        # Update label IDs for validation and training sets\n",
        "        names = update_label_id(labels_names_val, labels_val_dir, product_type_id) ### list names hinzuf√ºgen\n",
        "        names = update_label_id(labels_names_train, labels_train_dir, product_type_id)\n",
        "    else:\n",
        "        # Update label IDs for validation and training sets\n",
        "        names = update_label_names(labels_names_val, labels_val_dir, product_type_list_names)\n",
        "        names = update_label_names(labels_names_train, labels_train_dir, product_type_list_names)\n",
        "\n",
        "    # Define the YAML configuration structure\n",
        "    yolo_config = OrderedDict([\n",
        "      ('path', '../updatedDataset'),\n",
        "      ('train', 'images/train'),\n",
        "      ('val', 'images/val'),\n",
        "      ('test', ''),\n",
        "      ('names', names)\n",
        "    ])\n",
        "\n",
        "    # Function to represent OrderedDict as a standard YAML dictionary\n",
        "    def represent_ordereddict(dumper, data):\n",
        "        return dumper.represent_mapping('tag:yaml.org,2002:map', data.items())\n",
        "\n",
        "    yaml.add_representer(OrderedDict, represent_ordereddict)\n",
        "\n",
        "\n",
        "    # Write the configuration to a YAML file\n",
        "    with open('data.yaml', 'w') as file:\n",
        "        yaml.dump(yolo_config, file, default_flow_style=False)\n",
        "\n",
        "    print(\"YAML configuration file has been generated.\")\n"
      ],
      "metadata": {
        "id": "AaYw9chKclZA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_label_names(dataset_dir, format=\".txt\")\n",
        "for i in get_label_names(dataset_dir, format=\".txt\"):\n",
        "  path = dataset_dir + \"/\" + i\n",
        "  path = \"dataset\" + \"/\" + i\n",
        "  updated_path = \"updatedDataset\" + \"/\" + i\n",
        "  change_label_content(path, updated_path)\n",
        "  #copy images in folder with normalized labels\n",
        "copy_all_images(dataset_dir, updated_dataset_dir, get_jpg_image_names(dataset_dir))"
      ],
      "metadata": {
        "id": "mUYhrCdqaqIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1f8d8cc-53ec-4dff-e736-20f2d738db5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bathtub1 1 1 0.4960438863636364 0.43067268181818175 0.7551961363636364 0.48062636363636363', 'Faucet_Bathtub1 1 1 0.42926149999999996 0.19138201136363636 0.1471089090909091 0.08472297727272726']\n",
            "['Bathtub1 1 1 0.5255468181818181 0.43732784090909094 0.9303313636363636 0.40118386363636366', 'Faucet_Bathtub1 1 1 0.49072170454545455 0.21127753409090907 0.11622522727272727 0.09706011363636363']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "products = {\"Toilet\":0, \"Bathtub\":1, \"Sink\":2}\n",
        "create_yolo_training_config(\"updatedDataset\", product_specific=False, product_type_list_names=[\"Toilet\", \"Bathtub\", \"Sink\"])\n"
      ],
      "metadata": {
        "id": "7dn2_KCUazlz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406c01a1-dda1-4da9-8c44-86c235389384"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n",
            "{1: 'Bathtub'}\n",
            "YAML configuration file has been generated.\n"
          ]
        }
      ]
    }
  ]
}